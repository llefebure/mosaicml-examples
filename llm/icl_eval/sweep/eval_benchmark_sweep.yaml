
base_config:
  integrations:
    - integration_type: git_repo
      git_repo: mosaicml/examples
      git_branch: feature/composer_icl_eval
      pip_install: -r llm/requirements.txt

  # We are fetching, converting, and training on the 'val' split
  # as it is small and quick to get going for this demo.
  # For real training runs, follow the instructions in `examples/llm/README.md`
  # to convert and host the full 'train' dataset.
  command: |
    cd examples/llm
    composer -m icl_eval.evaluate_model /mnt/config/parameters.yaml

  image: mosaicml/pytorch:1.13.0_cu117-python3.10-ubuntu20.04
  optimization_level: 0

  run_name: mosaic-gpt-1b-eval
  gpu_num: 8
  gpu_type: a100_40gb
  cluster: r7z2 # replace with your cluster here!


  # The below is injected as a YAML file: /mnt/config/parameters.yaml
  # but is not used in this example.
  parameters:
    tokenizer:
      type: hftokenizer
      args:
        tokenizer_name: gpt2
        max_seq_len: 2048  
    model: {}
    icl_tasks: {}


sweep_config:
  gpu_num: 
    - 
      key: '64'
      value: 64
    - 
      key: '32'
      value: 32
    - 
      key: '16'
      value: 16
    - 
      key: '8'
      value: 8
 

  parameters.icl_tasks:
    -
      key:  lambada
      value:
        -
          label: lambada
          dataset_uri: s3://mosaicml-internal-dataset-lambda/lambada/lambada_test.json
          num_fewshot: 
              - 0
          batch_size: 16
          type: language_modeling
          metrics:
              - InContextLearningLMAccuracy
          formatting_options:
            prompt_string: ""
            example_delimiter: "\n"
            continuation_delimiter: ""
    -
      key:  piqa
      value:  
        -
          label: piqa
          dataset_uri: s3://mosaicml-internal-dataset-hellaswag/piqa.jsonz
          num_fewshot: 
              - 5
          batch_size: 16
          type: multiple_choice
          metrics:
              - InContextLearningMultipleChoiceAccuracy
          formatting_options:
            prompt_string: ""
            example_delimiter: "\n"
            continuation_delimiter: " "
  
  parameters.model:
    # -
    #   key: '125m'
    #   value:
    #     model_type: pretrained_hf
    #     config: EleutherAI/gpt-neo-125M
    -
      key: '1.3b'
      value:
        model_type: pretrained_hf
        config: EleutherAI/gpt-neo-1.3B
    # -
    #   key: '2.7b'
    #   value:
    #     model_type: pretrained_hf
    #     config: EleutherAI/gpt-neo-2.7B