base_config:
  integrations:
    - integration_type: git_repo
      git_repo: mosaicml/examples
      git_branch: feature/composer_icl_eval
      pip_install: -r llm/requirements.txt


  command: |
    cd examples/llm
    composer -m src.evaluation.eval  /mnt/config/parameters.yaml


  image: mosaicml/pytorch:1.13.0_cu117-python3.10-ubuntu20.04
  optimization_level: 0

  run_name: mosaic-gpt-1b-eval
  gpu_num: 8
  gpu_type: a100_40gb
  cluster: r7z2 # replace with your cluster here!


  # The below is injected as a YAML file: /mnt/config/parameters.yaml
  # but is not used in this example.
  parameters:
    tokenizer:
      type: hftokenizer
      args:
        tokenizer_name: gpt2
        max_seq_len: 2048  
    model: {}
    icl_tasks: {}
    outfile: icl_results.tsv


sweep_config:
  gpu_num: 
    - 
      key: '64'
      value: 64
    - 
      key: '32'
      value: 32
    - 
      key: '16'
      value: 16
    - 
      key: '8'
      value: 8
 
  parameters.icl_tasks:
    -
      key:  lambada
      value:
        -
          label: lambada
          num_fewshot: 
              - 0
    -
      key:  piqa
      value:  
        -
          label: piqa
          num_fewshot: 
              - 5
  
  parameters.model:
    -
      key: '125m'
      value:
        model_type: pretrained_hf
        config: EleutherAI/gpt-neo-125M
    -
      key: '1.3b'
      value:
        model_type: pretrained_hf
        config: EleutherAI/gpt-neo-1.3B
    -
      key: '2.7b'
      value:
        model_type: pretrained_hf
        config: EleutherAI/gpt-neo-2.7B